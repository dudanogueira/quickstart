{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weaviate quickstart guide (as a notebook!)\n",
    "\n",
    "This notebook will guide you through the basics of Weaviate. You can find the full documentation [on our site here](https://weaviate.io/developers/weaviate/quickstart)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weaviate instance\n",
    "\n",
    "For this, you will need a working instance of Weaviate somewhere. We recommend either:\n",
    "- Creating a free sandbox instance on Weaviate Cloud Services (https://console.weaviate.cloud/), or\n",
    "- Using [Embedded Weaviate](https://weaviate.io/developers/weaviate/installation/embedded).\n",
    "\n",
    "Instantiate the client using **one** of the following code examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For using WCS\n",
    "\n",
    "NOTE: Before you do this, you need to create the instance in WCS and get the credentials. Please refer to the [WCS Quickstart guide](https://weaviate.io/developers/wcs/quickstart)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For using WCS\n",
    "# import weaviate\n",
    "# import json\n",
    "# import os\n",
    "\n",
    "# client = weaviate.Client(\n",
    "#     url = \"https://some-endpoint.weaviate.network\",  # Replace with your endpoint\n",
    "#     auth_client_secret=weaviate.AuthApiKey(api_key=\"YOUR-WEAVIATE-API-KEY\"),  # Replace w/ your Weaviate instance API key\n",
    "#     additional_headers = {\n",
    "#         \"X-OpenAI-Api-Key\": os.environ[\"OPENAI_APIKEY\"]  # Replace with your inference API key\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For using Embedded Weaviate\n",
    "\n",
    "This will spin up a Weaviate instance in the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedded weaviate is already listening on port 6666\n"
     ]
    }
   ],
   "source": [
    "# For using embedded\n",
    "import weaviate\n",
    "from weaviate.embedded import EmbeddedOptions\n",
    "import json\n",
    "import os\n",
    "\n",
    "client = weaviate.Client(\n",
    "    embedded_options=EmbeddedOptions(),\n",
    "    additional_headers = {\n",
    "        \"X-OpenAI-Api-Key\": os.environ[\"OPENAI_APIKEY\"]  # Replace with your inference API key\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if client.schema.exists(\"Question\"):\n",
    "    client.schema.delete_class(\"Question\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_obj = {\n",
    "    \"class\": \"Question\",\n",
    "    \"vectorizer\": \"text2vec-openai\",  # If set to \"none\" you must always provide vectors yourself. Could be any other \"text2vec-*\" also.\n",
    "    \"moduleConfig\": {\n",
    "        \"text2vec-openai\": {},\n",
    "        \"generative-openai\": {}  # Ensure the `generative-openai` module is used for generative queries\n",
    "    }\n",
    "}\n",
    "\n",
    "client.schema.create_class(class_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add objects\n",
    "\n",
    "We'll add objects to our Weaviate instance using a batch import process.\n",
    "\n",
    "We shows you two options, where you can either:\n",
    "- Have Weaviate create vectors, or\n",
    "- Specify custom vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Have Weaviate create vectors (with `text2vec-openai`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing question: 1\n",
      "importing question: 2\n",
      "importing question: 3\n",
      "importing question: 4\n",
      "importing question: 5\n",
      "importing question: 6\n",
      "importing question: 7\n",
      "importing question: 8\n",
      "importing question: 9\n",
      "importing question: 10\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "import requests\n",
    "url = 'https://raw.githubusercontent.com/weaviate-tutorials/quickstart/main/data/jeopardy_tiny.json'\n",
    "resp = requests.get(url)\n",
    "data = json.loads(resp.text)\n",
    "\n",
    "# Configure a batch process\n",
    "with client.batch(\n",
    "    batch_size=100\n",
    ") as batch:\n",
    "    # Batch import all Questions\n",
    "    for i, d in enumerate(data):\n",
    "        print(f\"importing question: {i+1}\")\n",
    "\n",
    "        properties = {\n",
    "            \"answer\": d[\"Answer\"],\n",
    "            \"question\": d[\"Question\"],\n",
    "            \"category\": d[\"Category\"],\n",
    "        }\n",
    "\n",
    "        client.batch.add_data_object(\n",
    "            properties,\n",
    "            \"Question\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify \"custom\" vectors (i.e. generated outside of Weaviate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load data\n",
    "# import requests\n",
    "# fname = \"jeopardy_tiny_with_vectors_all-OpenAI-ada-002.json\"  # This file includes pre-generated vectors\n",
    "# url = f'https://raw.githubusercontent.com/weaviate-tutorials/quickstart/main/data/{fname}'\n",
    "# resp = requests.get(url)\n",
    "# data = json.loads(resp.text)\n",
    "\n",
    "# # Configure a batch process\n",
    "# with client.batch(\n",
    "#     batch_size=100\n",
    "# ) as batch:\n",
    "#     # Batch import all Questions\n",
    "#     for i, d in enumerate(data):\n",
    "#         print(f\"importing question: {i+1}\")\n",
    "\n",
    "#         properties = {\n",
    "#             \"answer\": d[\"Answer\"],\n",
    "#             \"question\": d[\"Question\"],\n",
    "#             \"category\": d[\"Category\"],\n",
    "#         }\n",
    "\n",
    "#         custom_vector = d[\"vector\"]\n",
    "#         client.batch.add_data_object(\n",
    "#             properties,\n",
    "#             \"Question\",\n",
    "#             vector=custom_vector  # Add custom vector\n",
    "#         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Semantic search\n",
    "\n",
    "Let's try a similarity search. We'll use nearText search to look for quiz objects most similar to biology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"data\": {\n",
      "        \"Get\": {\n",
      "            \"Question\": [\n",
      "                {\n",
      "                    \"answer\": \"DNA\",\n",
      "                    \"category\": \"SCIENCE\",\n",
      "                    \"question\": \"In 1953 Watson & Crick built a model of the molecular structure of this, the gene-carrying substance\"\n",
      "                },\n",
      "                {\n",
      "                    \"answer\": \"species\",\n",
      "                    \"category\": \"SCIENCE\",\n",
      "                    \"question\": \"2000 news: the Gunnison sage grouse isn't just another northern sage grouse, but a new one of this classification\"\n",
      "                }\n",
      "            ]\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "nearText = {\"concepts\": [\"biology\"]}\n",
    "\n",
    "response = (\n",
    "    client.query\n",
    "    .get(\"Question\", [\"question\", \"answer\", \"category\"])\n",
    "    .with_near_text(nearText)\n",
    "    .with_limit(2)\n",
    "    .do()\n",
    ")\n",
    "\n",
    "print(json.dumps(response, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The response includes a list of top 2 (due to the limit set) objects whose vectors are most similar to the word biology.\n",
    "\n",
    "Notice that even though the word biology does not appear anywhere, Weaviate returns biology-related entries.\n",
    "\n",
    "This example shows why vector searches are powerful. Vectorized data objects allow for searches based on degrees of similarity, as shown here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Semantic search with a filter\n",
    "You can add a Boolean filter to your example. For example, let's run the same search, but only look in objects that have a \"category\" value of \"ANIMALS\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"data\": {\n",
      "        \"Get\": {\n",
      "            \"Question\": [\n",
      "                {\n",
      "                    \"answer\": \"the nose or snout\",\n",
      "                    \"category\": \"ANIMALS\",\n",
      "                    \"question\": \"The gavial looks very much like a crocodile except for this bodily feature\"\n",
      "                },\n",
      "                {\n",
      "                    \"answer\": \"Elephant\",\n",
      "                    \"category\": \"ANIMALS\",\n",
      "                    \"question\": \"It's the only living mammal in the order Proboseidea\"\n",
      "                }\n",
      "            ]\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "nearText = {\"concepts\": [\"biology\"]}\n",
    "\n",
    "response = (\n",
    "    client.query\n",
    "    .get(\"Question\", [\"question\", \"answer\", \"category\"])\n",
    "    .with_near_text(nearText)\n",
    "    .with_where({\n",
    "        \"path\": [\"category\"],\n",
    "        \"operator\": \"Equal\",\n",
    "        \"valueText\": \"ANIMALS\"\n",
    "    })\n",
    "    .with_limit(2)\n",
    "    .do()\n",
    ")\n",
    "\n",
    "print(json.dumps(response, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The response includes a list of top 2 (due to the limit set) objects whose vectors are most similar to the word biology - but only from the \"ANIMALS\" category.\n",
    "\n",
    "Using a Boolean filter allows you to combine the flexibility of vector search with the precision of where filters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generative search\n",
    "\n",
    "Now let's try a generative search. We'll retrieve a set of results just as we did above, before using a large language model (LLM) to explain each answer in plain terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"data\": {\n",
      "        \"Get\": {\n",
      "            \"Question\": [\n",
      "                {\n",
      "                    \"_additional\": {\n",
      "                        \"generate\": {\n",
      "                            \"error\": null,\n",
      "                            \"singleResult\": \"DNA is like a special code that tells our bodies how to grow and work. It's like a recipe book that has all the instructions for making you who you are. Just like a recipe book tells you how to make yummy cookies, DNA tells your body how to make your eyes, hair, and even how tall you will be. It's really amazing because it's what makes you unique and different from everyone else!\"\n",
      "                        }\n",
      "                    },\n",
      "                    \"answer\": \"DNA\",\n",
      "                    \"category\": \"SCIENCE\",\n",
      "                    \"question\": \"In 1953 Watson & Crick built a model of the molecular structure of this, the gene-carrying substance\"\n",
      "                },\n",
      "                {\n",
      "                    \"_additional\": {\n",
      "                        \"generate\": {\n",
      "                            \"error\": null,\n",
      "                            \"singleResult\": \"Well, a species is a group of living things that are similar to each other in many ways. They have the same kind of body parts, like legs or wings, and they can have babies with other members of their species. For example, dogs are a species, and so are cats. They look different and act differently, but all dogs can have puppies with other dogs, and all cats can have kittens with other cats. So, a species is like a big family of animals or plants that are all related to each other in a special way.\"\n",
      "                        }\n",
      "                    },\n",
      "                    \"answer\": \"species\",\n",
      "                    \"category\": \"SCIENCE\",\n",
      "                    \"question\": \"2000 news: the Gunnison sage grouse isn't just another northern sage grouse, but a new one of this classification\"\n",
      "                }\n",
      "            ]\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "nearText = {\"concepts\": [\"biology\"]}\n",
    "\n",
    "response = (\n",
    "    client.query\n",
    "    .get(\"Question\", [\"question\", \"answer\", \"category\"])\n",
    "    .with_near_text(nearText)\n",
    "    .with_generate(single_prompt=\"Explain {answer} as you might to a five-year-old.\")\n",
    "    .with_limit(2)\n",
    "    .do()\n",
    ")\n",
    "\n",
    "print(json.dumps(response, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we see that Weaviate has retrieved the same results as before. But now it includes an additional, generated text with a plain-language explanation of each answer.\n",
    "\n",
    "Generative search sends retrieved data from Weaviate to a large language model, or LLM. This allows you to go beyond simple data retrieval, but transform the data into a more useful form, without ever leaving Weaviate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well done! In just a few short minutes, you have:\n",
    "\n",
    "- Created your own cloud-based vector database with Weaviate,\n",
    "- Populated it with data objects,\n",
    "    - Using an inference API, or\n",
    "    - Using custom vectors,\n",
    "- Performed searches, including:\n",
    "    - Semantic search,\n",
    "    - Sementic search with a filter and\n",
    "    - Generative search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
